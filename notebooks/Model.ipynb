{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import chi2_contingency\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BMI</th>\n",
       "      <th>MentHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "      <th>Age</th>\n",
       "      <th>HighBP_1</th>\n",
       "      <th>HighChol_1</th>\n",
       "      <th>Smoker_1</th>\n",
       "      <th>Stroke_1</th>\n",
       "      <th>Diabetes_1</th>\n",
       "      <th>PhysActivity_1</th>\n",
       "      <th>Fruits_1</th>\n",
       "      <th>Veggies_1</th>\n",
       "      <th>DiffWalk_1</th>\n",
       "      <th>Sex_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.667211</td>\n",
       "      <td>1.879070</td>\n",
       "      <td>1.141305</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.543127</td>\n",
       "      <td>-0.454439</td>\n",
       "      <td>-0.516790</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.101059</td>\n",
       "      <td>3.434743</td>\n",
       "      <td>2.799400</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.248415</td>\n",
       "      <td>-0.454439</td>\n",
       "      <td>-0.516790</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.690483</td>\n",
       "      <td>-0.065520</td>\n",
       "      <td>-0.516790</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        BMI  MentHlth  PhysHlth  GenHlth  Education  Income   Age  HighBP_1  \\\n",
       "0  1.667211  1.879070  1.141305      4.0        3.0     2.0   8.0       1.0   \n",
       "1 -0.543127 -0.454439 -0.516790      2.0        5.0     0.0   6.0       0.0   \n",
       "2 -0.101059  3.434743  2.799400      4.0        3.0     7.0   8.0       1.0   \n",
       "3 -0.248415 -0.454439 -0.516790      1.0        2.0     5.0  10.0       1.0   \n",
       "4 -0.690483 -0.065520 -0.516790      1.0        4.0     3.0  10.0       1.0   \n",
       "\n",
       "   HighChol_1  Smoker_1  Stroke_1  Diabetes_1  PhysActivity_1  Fruits_1  \\\n",
       "0         1.0       1.0       0.0         0.0             0.0       0.0   \n",
       "1         0.0       1.0       0.0         0.0             1.0       0.0   \n",
       "2         1.0       0.0       0.0         0.0             0.0       1.0   \n",
       "3         0.0       0.0       0.0         0.0             1.0       1.0   \n",
       "4         1.0       0.0       0.0         0.0             1.0       1.0   \n",
       "\n",
       "   Veggies_1  DiffWalk_1  Sex_1  \n",
       "0        1.0         1.0    0.0  \n",
       "1        0.0         0.0    0.0  \n",
       "2        0.0         1.0    0.0  \n",
       "3        1.0         0.0    0.0  \n",
       "4        1.0         0.0    0.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "df = pd.read_csv(r'https://raw.githubusercontent.com/Venkatalakshmikottapalli/Heart-Disease-Prediction/refs/heads/main/data/processed/Heart_disease.csv')\n",
    "#display the head of the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define x and y\n",
    "x = df.drop('"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Split the dataset into training and testing sets\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, stratify\u001b[38;5;241m=\u001b[39my)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comment:\n",
    "- Split the data into training and testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building & Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes classifier\n",
    "nb_classifier = GaussianNB()\n",
    "\n",
    "# Fit the model on the training data\n",
    "nb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = nb_classifier.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy of the Naive bayes model: {accuracy}\")\n",
    "\n",
    "# Calculate ROC-AUC score\n",
    "roc_auc_nb = roc_auc_score(y_test, nb_classifier.predict_proba(X_test)[:, 1])\n",
    "print(f\"ROC-AUC of the Naive Bayes model: {roc_auc_nb}\")\n",
    "\n",
    "# Define target names \n",
    "target_names = ['No Heart Disease', 'Heart Disease']\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred.reshape(-1, 1), target_names=target_names))\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm_naive = confusion_matrix(y_test, y_pred.reshape(-1, 1), normalize='true')\n",
    "print(cm_naive)\n",
    "\n",
    "# Display confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm_naive, display_labels=target_names)\n",
    "fig, ax = plt.subplots(figsize=(5, 3))\n",
    "disp.plot(ax=ax, cmap='Blues')\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Commnet:\n",
    "\n",
    "### Naive Bayes Model Performance\n",
    "\n",
    "The Naive Bayes model has an accuracy of **71.50%** and a ROC-AUC score of **0.80**, showing it can distinguish between heart disease and no heart disease effectively.\n",
    "- **Precision**:\n",
    "- No Heart Disease: **69%** (Out of those predicted as \"No Heart Disease,\" 69% were correct)\n",
    "- Heart Disease: **75%** (Out of those predicted as \"Heart Disease,\" 75% were correct)\n",
    "- **Recall**:\n",
    "- No Heart Disease: **78%** (Out of all actual \"No Heart Disease\" cases, 78% were correctly identified)\n",
    "- Heart Disease: **65%** (Out of all actual \"Heart Disease\" cases, 65% were correctly identified)\n",
    "- **F1-Score**:\n",
    "- No Heart Disease: **73%** (A balance between precision and recall for \"No Heart Disease\")\n",
    "- Heart Disease: **70%** (A balance between precision and recall for \"Heart Disease\")\n",
    "- With a total of **82,420** predictions, the macro and weighted averages for precision, recall, and F1-score are around **0.72** to **0.71**, indicating balanced performance. The confusion matrix highlights some misclassifications of heart disease cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the Decision Tree classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Fit the model on the training data\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy of the Decision Tree model: {accuracy}\")\n",
    "\n",
    "# Calculate ROC-AUC score\n",
    "roc_auc_dt = roc_auc_score(y_test, dt_classifier.predict_proba(X_test)[:, 1])\n",
    "print(f\"ROC-AUC of the Decision Tree model: {roc_auc_dt}\")\n",
    "\n",
    "# Define target names \n",
    "target_names = ['No Heart Disease', 'Heart Disease']\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm_decisiontree = confusion_matrix(y_test, y_pred, normalize='true')\n",
    "print(cm_decisiontree)\n",
    "\n",
    "# Display confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm_decisiontree, display_labels=target_names)\n",
    "fig, ax = plt.subplots(figsize=(5, 3))\n",
    "disp.plot(ax=ax, cmap='Blues')\n",
    "plt.title(\"Confusion Matrix for Decision Tree\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comment:\n",
    "\n",
    "### Decision Tree Model Performance\n",
    "\n",
    "The Decision Tree model has an accuracy of **90.06%** and a ROC-AUC score of **0.90**, indicating strong performance in distinguishing between heart disease and no heart disease.\n",
    "- **Precision**:\n",
    "- No Heart Disease: **91%** (Out of those predicted as \"No Heart Disease,\" 91% were correct)\n",
    "- Heart Disease: **90%** (Out of those predicted as \"Heart Disease,\" 90% were correct)\n",
    "- **Recall**:\n",
    "- No Heart Disease: **89%** (Out of all actual \"No Heart Disease\" cases, 89% were correctly identified)\n",
    "- Heart Disease: **91%** (Out of all actual \"Heart Disease\" cases, 91% were correctly identified)\n",
    "- **F1-Score**:\n",
    "- No Heart Disease: **90%** (A balance between precision and recall for \"No Heart Disease\")\n",
    "-  Heart Disease: **90%** (A balance between precision and recall for \"Heart Disease\")\n",
    "- With a total of **82,420** predictions, the macro and weighted averages for precision, recall, and F1-score are around **0.90**, indicating balanced performance. The confusion matrix suggests minimal misclassifications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the Logistic Regression classifier\n",
    "log_reg_classifier = LogisticRegression(max_iter=1000)  \n",
    "\n",
    "# Fit the model on the training data\n",
    "log_reg_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = log_reg_classifier.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy of the Logistic Regression model: {accuracy}\")\n",
    "\n",
    "# Calculate ROC-AUC score\n",
    "roc_auc_lr = roc_auc_score(y_test, log_reg_classifier.predict_proba(X_test)[:, 1])\n",
    "print(f\"ROC-AUC of the Logistic Regression model: {roc_auc_lr}\")\n",
    "\n",
    "# Define target names \n",
    "target_names = ['No Heart Disease', 'Heart Disease']\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm_lr = confusion_matrix(y_test, y_pred, normalize='true')\n",
    "print(cm_lr)\n",
    "\n",
    "# Display confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm_lr, display_labels=target_names)\n",
    "fig, ax = plt.subplots(figsize=(5, 3))\n",
    "disp.plot(ax=ax, cmap='Blues')\n",
    "plt.title(\"Confusion Matrix for Logistic Regression\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comment:\n",
    "\n",
    "### Logistic Regression Model Performance\n",
    "\n",
    "The Logistic Regression model has an accuracy of **76.47%** and a ROC-AUC score of **0.84**, indicating a good ability to distinguish between heart disease and no heart disease.\n",
    "- **Precision**:\n",
    "- No Heart Disease: **78%** (Out of those predicted as \"No Heart Disease,\" 78% were correct)\n",
    "- Heart Disease: **75%** (Out of those predicted as \"Heart Disease,\" 75% were correct)\n",
    "- **Recall**:\n",
    "- No Heart Disease: **74%** (Out of all actual \"No Heart Disease\" cases, 74% were correctly identified)\n",
    "- Heart Disease: **79%** (Out of all actual \"Heart Disease\" cases, 79% were correctly identified)\n",
    "- **F1-Score**:\n",
    "- No Heart Disease: **76%** (A balance between precision and recall for \"No Heart Disease\")\n",
    "- Heart Disease: **77%** (A balance between precision and recall for \"Heart Disease\")\n",
    "- With a total of **82,420** predictions, the macro and weighted averages for precision, recall, and F1-score are around **0.77** to **0.76**, indicating balanced performance. The confusion matrix shows some misclassifications of heart disease cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Fit the model on the training data\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy of the Random Forest model: {accuracy}\")\n",
    "\n",
    "# Calculate ROC-AUC score\n",
    "roc_auc_rf = roc_auc_score(y_test, rf_classifier.predict_proba(X_test)[:, 1])\n",
    "print(f\"ROC-AUC of the Random Forest model: {roc_auc_rf}\")\n",
    "\n",
    "# Define target names \n",
    "target_names = ['No Heart Disease', 'Heart Disease']\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm_rf = confusion_matrix(y_test, y_pred, normalize='true')\n",
    "print(cm_rf)\n",
    "\n",
    "# Display confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm_rf, display_labels=target_names)\n",
    "fig, ax = plt.subplots(figsize=(5, 3))\n",
    "disp.plot(ax=ax, cmap='Blues')\n",
    "plt.title(\"Confusion Matrix for Random Forest\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Model Performance\n",
    "\n",
    "The Random Forest model achieved an accuracy of **94.08%** and a ROC-AUC score of **0.98**, indicating its strong ability to distinguish between heart disease and no heart disease.\n",
    "\n",
    "- **Precision**:\n",
    "- No Heart Disease: **92%** (Out of those predicted as \"No Heart Disease,\" 92% were correct)\n",
    "- Heart Disease: **96%** (Out of those predicted as \"Heart Disease,\" 96% were correct)\n",
    "\n",
    "- **Recall**:\n",
    "- No Heart Disease: **96%** (Out of all actual \"No Heart Disease\" cases, 96% were correctly identified)\n",
    "- Heart Disease: **92%** (Out of all actual \"Heart Disease\" cases, 92% were correctly identified)\n",
    "\n",
    "- **F1-Score**:\n",
    "- No Heart Disease: **94%** (A balance between precision and recall for \"No Heart Disease\")\n",
    "- Heart Disease: **94%** (A balance between precision and recall for \"Heart Disease\")\n",
    "\n",
    "- With a total of **82,420** predictions, the macro and weighted averages for precision, recall, and F1-score are all approximately **0.94**, indicating consistent performance across both classes. The confusion matrix reveals the model's effectiveness in minimizing misclassifications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the Gradient Boosting classifier\n",
    "gb_classifier = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# Fit the model on the training data\n",
    "gb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = gb_classifier.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy of the Gradient Boosting model: {accuracy}\")\n",
    "\n",
    "# Calculate ROC-AUC score\n",
    "roc_auc_gb = roc_auc_score(y_test, gb_classifier.predict_proba(X_test)[:, 1])\n",
    "print(f\"ROC-AUC of the Gradient Boosting model: {roc_auc_gb}\")\n",
    "\n",
    "# Define target names \n",
    "target_names = ['No Heart Disease', 'Heart Disease']\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm_gb = confusion_matrix(y_test, y_pred, normalize='true')\n",
    "print(cm_gb)\n",
    "\n",
    "# Display confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm_gb, display_labels=target_names)\n",
    "fig, ax = plt.subplots(figsize=(5, 3))\n",
    "disp.plot(ax=ax, cmap='Blues')\n",
    "plt.title(\"Confusion Matrix for Gradient Boosting\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comment:\n",
    "\n",
    "### Gradient Boosting Model Performance\n",
    "\n",
    "The Gradient Boosting model has an accuracy of **89.48%** and a ROC-AUC score of **0.96**, demonstrating a strong ability to distinguish between heart disease and no heart disease.\n",
    "- **Precision**:\n",
    "  - No Heart Disease: **90%** (Out of those predicted as \"No Heart Disease,\" 90% were correct)\n",
    "  - Heart Disease: **89%** (Out of those predicted as \"Heart Disease,\" 89% were correct)\n",
    "- **Recall**:\n",
    "  - No Heart Disease: **89%** (Out of all actual \"No Heart Disease\" cases, 89% were correctly identified)\n",
    "  - Heart Disease: **90%** (Out of all actual \"Heart Disease\" cases, 90% were correctly identified)\n",
    "- **F1-Score**:\n",
    "  - No Heart Disease: **89%** (A balance between precision and recall for \"No Heart Disease\")\n",
    "  - Heart Disease: **90%** (A balance between precision and recall for \"Heart Disease\")\n",
    "- With a total of **82,420** predictions, the macro and weighted averages for precision, recall, and F1-score are around **0.89**, indicating balanced performance. The confusion matrix reflects minimal misclassifications of heart disease cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the XGBoost classifier\n",
    "xgb_classifier = xgb.XGBClassifier(random_state=42)\n",
    "\n",
    "# Fit the model on the training data\n",
    "xgb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = xgb_classifier.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy of the XGBoost model: {accuracy}\")\n",
    "\n",
    "# Calculate ROC-AUC score\n",
    "roc_auc_xgb = roc_auc_score(y_test, xgb_classifier.predict_proba(X_test)[:, 1])\n",
    "print(f\"ROC-AUC of the XGBoost model: {roc_auc_xgb}\")\n",
    "\n",
    "# Define target names \n",
    "target_names = ['No Heart Disease', 'Heart Disease']\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm_xgb = confusion_matrix(y_test, y_pred, normalize='true')\n",
    "print(cm_xgb)\n",
    "\n",
    "# Display confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm_xgb, display_labels=target_names)\n",
    "fig, ax = plt.subplots(figsize=(5, 3))\n",
    "disp.plot(ax=ax, cmap='Blues')\n",
    "plt.title(\"Confusion Matrix for XGBoost\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comment:\n",
    "\n",
    "### XGBoost Model Performance\n",
    "\n",
    "The XGBoost model has an accuracy of **93.87%** and a ROC-AUC score of **0.98**, indicating excellent capability in distinguishing between heart disease and no heart disease.\n",
    "- **Precision**:\n",
    "  - No Heart Disease: **90%** (Out of those predicted as \"No Heart Disease,\" 90% were correct)\n",
    "  - Heart Disease: **98%** (Out of those predicted as \"Heart Disease,\" 98% were correct)\n",
    "- **Recall**:\n",
    "  - No Heart Disease: **99%** (Out of all actual \"No Heart Disease\" cases, 99% were correctly identified)\n",
    "  - Heart Disease: **89%** (Out of all actual \"Heart Disease\" cases, 89% were correctly identified)\n",
    "- **F1-Score**:\n",
    "  - No Heart Disease: **94%** (A balance between precision and recall for \"No Heart Disease\")\n",
    "  - Heart Disease: **94%** (A balance between precision and recall for \"Heart Disease\")\n",
    "- With a total of **82,420** predictions, the macro and weighted averages for precision, recall, and F1-score are around **0.94**, indicating balanced performance. The confusion matrix shows a high rate of correct classifications, especially for \"No Heart Disease.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Define the model\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Define a more expanded parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100],  \n",
    "    'max_depth': [None, 10, 20, 30],  \n",
    "    'max_features': ['sqrt', 'log2'],  \n",
    "    'criterion': ['entropy'],  \n",
    "    'bootstrap': [True, False]                \n",
    "}\n",
    "\n",
    "# Set up the randomized search with more iterations\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rf_model, \n",
    "    param_distributions=param_grid, \n",
    "    n_iter=20, \n",
    "    scoring='accuracy',  \n",
    "    cv=5,  \n",
    "    verbose=1, \n",
    "    random_state=42,\n",
    "    n_jobs=-1  \n",
    ")\n",
    "\n",
    "# Fit the randomized search \n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and best score\n",
    "print(\"Best Parameters:\", random_search.best_params_)\n",
    "print(\"Best Score:\", random_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the best estimator from the random search\n",
    "best_rf_model = random_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = best_rf_model.predict(X_test)\n",
    "\n",
    "# Calculate and print evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm_gb = confusion_matrix(y_test, y_pred, normalize='true')\n",
    "print(cm_gb)\n",
    "\n",
    "# Print them\n",
    "print(\"Model Evaluation Metrics:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "\n",
    "# Print classification report \n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impact of Hyperparameter Tuning\n",
    "- Despite applying extensive hyperparameter tuning, the improvements in accuracy, precision, recall, and F1 score were minimal. Tuning did not significantly enhance the model's performance; therefore, the original model, without tuning, will be retained as it offers comparable results with less complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Model - Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Fit the model on the training data\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy of the Random Forest model: {accuracy}\")\n",
    "\n",
    "# Calculate ROC-AUC score\n",
    "roc_auc_rf = roc_auc_score(y_test, rf_classifier.predict_proba(X_test)[:, 1])\n",
    "print(f\"ROC-AUC of the Random Forest model: {roc_auc_rf}\")\n",
    "\n",
    "# Define target names \n",
    "target_names = ['No Heart Disease', 'Heart Disease']\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm_rf = confusion_matrix(y_test, y_pred, normalize='true')\n",
    "print(cm_rf)\n",
    "\n",
    "# Display confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm_rf, display_labels=target_names)\n",
    "fig, ax = plt.subplots(figsize=(5, 3))\n",
    "disp.plot(ax=ax, cmap='Blues')\n",
    "plt.title(\"Confusion Matrix for Random Forest\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "- After testing multiple models, I selected Random Forest for its high accuracy and excellent ROC-AUC, ensuring reliable predictions. Future improvements could involve neural networks and a user-friendly interface. Overall, the Random Forest model is recommended for effective heart disease risk prediction, offering valuable insights for preventive care."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 1690571,
     "sourceId": 3277449,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30664,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
